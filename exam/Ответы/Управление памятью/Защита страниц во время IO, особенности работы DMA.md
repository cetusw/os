#### **Что означает блокировка страницы (locking/pinning) в контексте замещения страниц? ⭐⭐**
Это установка специального флага в дескрипторе страницы, который прямо запрещает алгоритму замещения выбирать эту страницу в качестве «жертвы». Страница «пришпиливается» к конкретному физическому кадру.

#### **Почему pinning считается “надёжным” решением для DMA и не требует копирования данных? ⭐⭐**
Потому что он гарантирует, что физический адрес, который ОС дала контроллеру DMA, останется неизменным и будет принадлежать правильному буферу до самого конца операции. Данные пишутся сразу «куда надо» пользователю.

#### **Какие условия должны выполняться, чтобы ОС могла безопасно снять блокировку страницы после завершения I/O? ⭐⭐**
1. Устройство должно прислать прерывание о завершении передачи.
2. Обработчик прерывания должен подтвердить, что все данные успешно записаны/прочитаны.
3. Счетчик активных I/O операций для этой страницы (если их несколько) должен обнулиться.

#### **Какие системные проблемы появляются, если слишком много страниц закреплено (pinned) одновременно? ⭐⭐⭐**
Объем памяти, доступный для маневра алгоритму замещения, резко сокращается. Если закрепить слишком много страниц, система войдет в состояние **thrashing** даже при наличии свободной физической памяти, так как «незакрепленных» кадров не хватит для поддержания рабочих множеств процессов. В худшем случае ОС не сможет найти ни одного кадра для обработки очередного *page fault*.

#### **Почему pinning может “умеренно увеличить задержки подкачки”, даже если он защищает данные? ⭐⭐**
Потому что он сужает выбор для алгоритма замещения. ОС приходится вытеснять более «свежие» (и чаще используемые) страницы просто потому, что старые и редкие страницы сейчас «закреплены» под I/O. Это ведет к учащению *page faults*.

#### **Какие страницы типично блокируются в ОС помимо пользовательских буферов (например, метаданные, буферы драйверов)? ⭐⭐⭐**
*   Код и структуры данных самого ядра.
*   Таблицы страниц.
*   Векторы прерываний.
*   Буферы для сетевых карт (кольцевые буферы дескрипторов).

#### **Почему pinning усложняет работу алгоритма замещения (например, уменьшается число кандидатов на вытеснение)? ⭐⭐⭐**
Алгоритм замещения (например, Clock) вынужден «пропускать» заблокированные страницы. Это увеличивает время поиска подходящей жертвы и заставляет алгоритм принимать неоптимальные решения (вытеснять «хорошие» страницы вместо «плохих», но заблокированных).

#### **Какие ошибки проектирования могут привести к “утечке pinned-страниц” и деградации системы? ⭐⭐⭐**
Если драйвер устройства инициирует I/O, блокирует страницу, но из-за бага не снимает блокировку при ошибке устройства или отмене операции. Со временем «забытые» заблокированные страницы съедят всю RAM, и система «задохнется».

#### **Сравните pinning с “запретом выгрузки” на уровне процесса: чем отличается по эффекту и рискам? ⭐⭐**
*   **Pinning:** Краткосрочный, на уровне отдельных страниц, управляется ядром для нужд I/O. Риск минимален.
*   **Запрет выгрузки (mlock):** Долгосрочный, на уровне всего процесса, инициируется пользователем. Риск: один вредоносный или кривой процесс может забрать всю память системы и «повесить» её.

#### **Как работает схема “I/O в буфер ядра, потом копирование в память процесса”? ⭐⭐**
1. Ядро выделяет свой кадр (который гарантированно не выгружается).
2. DMA пишет данные туда.
3. После прерывания CPU выполняет команду копирования данных из буфера ядра в виртуальную память процесса.
4. Буфер ядра освобождается.

#### **Почему это решение проще с точки зрения корректности, но хуже по производительности? ⭐⭐**
*   **Проще:** Нет нужды блокировать/разблокировать страницы пользователя и следить за их состоянием.
*   **Хуже:** Двойная работа. Сначала данные передаются по шине I/O, потом CPU тратит время на копирование внутри RAM. Это создает «бутылочное горлышко» в процессоре.

#### **В каких случаях ОС вынуждена использовать kernel buffering вместо pinning? ⭐⭐⭐**
Если пользовательский буфер не выровнен по границе страницы или если архитектура DMA имеет ограничения (например, умеет писать только в первые 16 МБ физической памяти — «legacy DMA»). Также это используется, когда данные нужно предварительно обработать (проверить контрольные суммы, распаковать заголовки пакетов).

#### **Почему лишнее копирование особенно дорого при высоких скоростях устройств (NVMe, 10/100GbE)? ⭐⭐**
Потому что скорость современных накопителей и сетей сопоставима со скоростью копирования памяти самим процессором. Копирование превращается в главный тормоз системы.

#### **Как kernel buffering влияет на кэширование страниц и вероятность thrashing? ⭐⭐⭐**
Использование буферов ядра увеличивает общую потребность в RAM (нужна память и пользователю, и ядру одновременно). Это «поджимает» память процессов, повышая риск thrashing. Однако, если ядро кэширует эти данные (например, дисковый кэш), это может помочь другим процессам прочитать тот же файл быстрее.

#### **Почему непрерывный виртуальный буфер может соответствовать разнесённым физическим страницам? ⭐⭐**
Потому что виртуальная память разбивает адресное пространство на страницы по 4 КБ. Процесс видит их как одну ленту, но в RAM они могут лежать в абсолютно случайных кадрах в зависимости от того, какие были свободны в момент выделения.

#### **Объясните, почему “разнесённость физических страниц” осложняет DMA-передачу. ⭐⭐**
Классический DMA-контроллер принимает «адрес начала» и «длину». Если ваш буфер в 64 КБ разбит на 16 физических кадров по 4 КБ в разных концах RAM, одним простым запросом к DMA данные не передать. Придется делать 16 маленьких запросов.

#### **Что такое scatter/gather DMA и какую проблему он решает? ⭐⭐**
Это продвинутый DMA, который умеет принимать **список** адресов и длин.
**Решаемая проблема:** Он позволяет передать большой виртуально-непрерывный буфер, разбросанный по RAM, за одну операцию.

#### **Почему список сегментов (физический адрес + длина) позволяет устройству выполнить одну “логическую” передачу как серию физических? ⭐⭐**
Контроллер DMA читает первую запись из списка, передает данные, затем сам берет следующую запись и продолжает передачу в новый физический адрес, пока список не закончится. Для ОС это выглядит как одна транзакция.

#### **В чём смысл batching: почему одно прерывание по завершении всей серии передач лучше, чем много прерываний? ⭐⭐**
Прерывание — дорогая операция (переключение контекста, сброс конвейера CPU). Получить 1 прерывание на 1 МБ данных гораздо выгоднее, чем 256 прерываний (по одному на каждую страницу 4 КБ).

#### **Как scatter/gather снижает накладные расходы CPU и повышает пропускную способность I/O? ⭐⭐**
*   **Снижение расходов:** CPU тратит время только на формирование списка сегментов один раз.
*   **Пропускная способность:** Устройство работает без пауз, которые возникли бы, если бы CPU настраивал DMA заново после каждой страницы.

#### **Почему scatter/gather полезен не только для пользовательских буферов, но и для подкачки страниц (page-in/page-out)? ⭐⭐⭐**
Когда ОС вытесняет страницы в swap, она старается писать их блоками для скорости. Эти страницы могут принадлежать разным процессам и лежать в RAM вразнобой. Scatter/gather позволяет собрать их и записать на диск одним «залпом».

#### **Какие риски для безопасности/изоляции возникают, если ОС неверно сформирует scatter/gather список? ⭐⭐⭐**
Устройство может прочитать или перезаписать чужие данные. Если в список случайно попадет адрес страницы с паролями другого процесса, контроллер DMA послушно отправит её на диск или в сеть. Это критическая дыра в безопасности.
