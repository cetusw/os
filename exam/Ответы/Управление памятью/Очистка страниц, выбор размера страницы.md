#### **Почему системе нужен резерв чистых кадров, и что происходит, если “почти все страницы dirty”? ⭐⭐**
**Резерв чистых кадров** — это пул физических кадров, данные в которых либо пусты, либо уже синхронизированы с диском.
*   **Зачем нужен:** Чтобы при возникновении *page fault* ОС могла мгновенно предоставить процессу страницу. Если чистых страниц нет, ОС придется сначала выбрать «грязную» (*dirty*) страницу, записать её на диск (дождаться окончания I/O), и только потом прочитать нужные данные. Это удваивает задержку.
*   **Если почти все dirty:** Производительность системы падает. Любой запрос на новую память вызывает блокировку процесса на время записи старых данных. Система начинает «заикаться».

#### **Какую роль выполняет paging daemon и почему это фоновая задача, а не часть обработки каждого page fault? ⭐⭐**
**Paging daemon** (фоновый процесс подкачки) периодически просыпается, чтобы проверить состояние памяти.
*   **Его роль:** Поддерживать количество свободных/чистых кадров выше определенного порога. Он ищет редко используемые страницы, и если они «грязные», инициирует их запись на диск заранее.
*   **Почему фоновая:** Обработка *page fault* должна быть максимально быстрой. Если встраивать в неё еще и поиск жертв с записью на диск, время отклика системы станет неприемлемым. Демон делает «грязную работу» в моменты низкой активности CPU/диска.

#### **Опишите жизненный цикл dirty-страницы: когда она становится dirty и когда/почему должна попасть на диск. ⭐⭐**
1.  **Рождение:** Страница загружается в кадр (она пока *clean*).
2.  **Загрязнение:** Процесс выполняет инструкцию записи (`STORE`) по адресу в этой странице. Аппаратура (MMU) автоматически выставляет *dirty-бит* (бит модификации) в таблице страниц.
3.  **Ожидание:** Страница живет в памяти.
4.  **Вытеснение/Очистка:** Либо *paging daemon* решит сбросить её на диск заранее, либо алгоритм замещения выберет её как жертву.
5.  **Запись:** Данные пишутся в файл или swap. После подтверждения записи бит *dirty* сбрасывается — страница снова *clean* и может быть удалена из RAM в любой момент без потери данных.

#### **В чём идея двух стрелок (two-handed clock): что делает передняя рука и что делает задняя? ⭐⭐**
Это модификация алгоритма «Часы» (Clock) для ускорения поиска жертв.
*   **Передняя рука (Leading hand):** Идет впереди. Она сбрасывает бит обращения (*Referenced bit*) в 0 у всех страниц, что встречает.
*   **Задняя рука (Trailing hand):** Идет следом на фиксированном расстоянии. Если она видит, что бит *R* всё еще 0, значит, к странице не обращались, пока между руками шло время. Она выбирает эту страницу для удаления или (если она dirty) отдает демону на запись.
```text
      Передняя (сброс R)
         \    /
      [][][][][][][]  <-- Кольцо страниц
         /    \
      Задняя (проверка R=0)
```

#### **Почему two-handed clock повышает шанс, что “в момент надобности” найдётся чистая страница, и как это влияет на latency page fault? ⭐⭐⭐**
За счет зазора между руками. Система получает «окно времени», чтобы успеть записать грязную страницу на диск до того, как задняя рука окончательно её выселит.
*   **Влияние на latency:** Это гарантирует, что к моменту, когда задняя рука дойдет до страницы, она с большой вероятностью уже будет *clean*. Следовательно, при *page fault* ОС просто берет готовый чистый кадр, что минимизирует задержку (не надо ждать записи).

#### **Как выбор интервалов пробуждения paging daemon влияет на производительность и “шум” I/O? ⭐⭐⭐**
*   **Частое пробуждение:** Память всегда «свежая», много чистых кадров. **Минус:** Постоянная нагрузка на диск («шум»), CPU тратит время на сканирование таблиц, страницы вытесняются слишком рано (могут понадобиться снова).
*   **Редкое пробуждение:** Меньше нагрузки на диск. **Минус:** Риск внезапного исчерпания чистых кадров, что приведет к резким скачкам задержек (*latency spikes*) при запросах памяти.

#### **Приведите пример, когда слишком агрессивная очистка страниц ухудшит производительность. ⭐⭐⭐**
Сценарий: процесс активно обновляет большую базу данных в памяти. Агрессивный демон постоянно записывает эти страницы на диск. Но процесс тут же снова пишет в них. В итоге диск перегружен бессмысленной записью промежуточных состояний, которые всё равно через миллисекунду станут неактуальными.

#### **Почему размер страницы — это компромисс между фрагментацией и накладными расходами таблиц страниц? ⭐⭐**
*   **Внутренняя фрагментация:** Потеря места в конце последней страницы процесса.
*   **Накладные расходы:** Память, занимаемая самими таблицами страниц.

#### **Объясните, что такое внутренняя фрагментация и почему она растёт при больших страницах. ⭐⭐**
Если процессу нужно 5 КБ памяти, а размер страницы 4 КБ, ОС даст ему 2 страницы (8 КБ). 3 КБ останутся пустыми и недоступными другим — это **внутренняя фрагментация**. Чем больше страница (например, 2 МБ), тем больше в среднем памяти «выкидывается» (в среднем $p/2$ на сегмент).

#### **Почему маленькие страницы увеличивают нагрузку на таблицы страниц и TLB? ⭐⭐**
1.  **Таблицы страниц:** Чтобы описать 4 ГБ памяти при страницах 4 КБ, нужно 1 млн записей. При страницах 1 КБ — 4 млн записей. Таблицы съедают RAM.
2.  **TLB:** Кэш трансляций в процессоре имеет ограниченное число слотов (например, 512). Маленькие страницы покрывают малую область памяти. Процесс, прыгая по памяти, будет постоянно вызывать промахи TLB (*TLB miss*), что сильно замедляет CPU.

#### **Как большие страницы могут ускорять работу с диском (I/O) и почему это не всегда выигрывает? ⭐⭐**
*   **Ускорение:** Читать/писать один блок в 64 КБ быстрее, чем 16 блоков по 4 КБ (меньше накладных расходов на позиционирование головок и команды контроллеру).
*   **Почему не всегда выигрыш:** Читая огромную страницу ради одного байта, мы тратим время и шину I/O на загрузку ненужных данных (*read amplification*), забивая память мусором.

#### **В формуле перерасхода overhead = s·e/p + p/2 объясните смысл каждого слагаемого “по-русски”. ⭐⭐⭐**
*   $s$ — средний размер процесса (в байтах).
*   $e$ — размер одной записи в таблице страниц (например, 8 байт).
*   $p$ — размер страницы.
1.  **$s \cdot e / p$:** Это суммарный размер таблицы страниц для процесса. Мы делим объем процесса на размер страницы, чтобы узнать число страниц, и умножаем на вес одной записи.
2.  **$p / 2$:** Это средняя потеря на внутреннюю фрагментацию (в среднем последний блок заполнен наполовину).

#### **Как выводится оптимум p = √(2se) (по смыслу, без полного матанализа) и что он означает? ⭐⭐⭐**
Оптимум находится там, где «встречаются» две беды: огромные таблицы страниц (при малых $p$) и огромная фрагментация (при больших $p$). Если взять производную от формулы выше и приравнять к нулю, получим этот корень. Он означает идеальный баланс, при котором суммарные потери памяти минимальны для данной нагрузки.

#### **Почему в примере с типичными параметрами получается около 4 КБ, и почему это стало “стандартом”? ⭐⭐**
Исторически, при средних размерах программ в 70-80-х годах и 4-8 байтовых записях в таблицах, формула давала значения около 4 КБ. Это значение закрепилось в архитектуре процессоров (x86). Переход на другой размер страницы требует переделки аппаратуры и ОС, поэтому 4 КБ остается «базовым» кирпичом.

#### **Что такое Transparent Huge Pages (THP) и какие выгоды/риски они несут (например, latency spikes, фрагментация)? ⭐⭐⭐**
Это механизм, когда ОС автоматически объединяет группы по 512 обычных страниц (4 КБ) в одну «огромную» страницу (2 МБ).
*   **Выгоды:** Резко снижается число промахов TLB, ускоряются тяжелые вычисления (БД, HPC).
*   **Риски:** 
    *   *Latency spikes:* Когда ОС в фоне пытается собрать огромную страницу из маленьких, она «замораживает» память.
    *   *Memory waste:* Если процессу нужно 5 КБ, а THP выделит 2 МБ, потери памяти будут колоссальными.

#### **Почему “разные размеры страниц для разных частей системы” могут быть разумной стратегией? ⭐⭐**
Для кода ядра и больших буферов видеокарты выгодно использовать Huge Pages (высокая скорость, низкий overhead). Для мелких пользовательских утилит выгодны страницы 4 КБ (экономия RAM). Современные процессоры поддерживают одновременную работу с разными размерами страниц.
