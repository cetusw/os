#### **Что такое виртуальная память и какие проблемы она решает в ОС? ⭐**
**Виртуальная память** — это абстракция, которая отделяет логическое представление памяти (как её видит процесс) от физического устройства (планок RAM и диска).
**Решаемые проблемы:**
1.  **Недостаток объема:** Позволяет запускать программы, размер которых превышает объем физической оперативной памяти (RAM).
2.  **Изоляция и безопасность:** Каждый процесс живет в своем адресном пространстве и не может «случайно» прочитать или изменить память соседа.
3.  **Фрагментация:** ОС может выделить процессу непрерывный диапазон логических адресов, даже если физические кадры разбросаны по всей RAM.
4.  **Совместное использование:** Позволяет нескольким процессам отображать одни и те же физические страницы (например, общие библиотеки) в свои разные виртуальные пространства.

#### **Чем различаются страница (page) и кадр/фрейм (frame), и почему это различие принципиально? ⭐**
*   **Страница (Page):** Единица *виртуальной* памяти. Это логический блок данных в адресном пространстве процесса.
*   **Кадр/Фрейм (Frame):** Единица *физической* памяти (RAM). Это «посадочное место», куда загружается страница.
**Принципиальное различие:** Разделение этих понятий позволяет реализовать динамическое отображение. Виртуальная страница №5 может находиться в физическом кадре №100 сегодня и в кадре №200 завтра, или вовсе быть вытеснена на диск. Это дает ОС гибкость в управлении ресурсами.

#### **Какие цели преследует алгоритм замещения страниц, кроме “освободить место”? ⭐⭐**
1.  **Минимизация Page Faults:** Главная цель — предсказать, какая страница не понадобится в ближайшее время, чтобы избежать дорогостоящих обращений к диску.
2.  **Справедливость (Fairness):** Гарантировать, что один «прожорливый» процесс не заберет себе всю память, парализовав остальные.
3.  **Снижение нагрузки на диск:** Избегать частого вытеснения «грязных» (измененных) страниц, так как их запись на диск требует времени.
4.  **Энергоэффективность:** В мобильных ОС — минимизация лишних циклов записи/чтения.

#### **Какие метрики производительности чаще всего используют для оценки работы подсистемы памяти (page fault rate, latency, throughput и т.п.) и почему? ⭐⭐**
*   **Page Fault Rate (Частота ошибок):** Количество промахов в единицу времени. Напрямую коррелирует с деградацией скорости.
*   **Minor vs Major Page Faults:** Minor (страница в памяти, но не в таблице процесса) — дешево; Major (чтение с диска) — очень дорого.
*   **Resident Set Size (RSS):** Объем физической памяти, занимаемой процессом. Помогает понять «прожорливость».
*   **Latency (Задержка доступа):** Время ожидания данных. Важно для интерактивности.
*   **Disk I/O Wait:** Доля времени, когда CPU простаивает, ожидая подкачки страниц.

#### **Объясните, почему “меньше page fault” не всегда означает “быстрее система”. ⭐⭐**
Иногда алгоритм тратит слишком много ресурсов CPU на то, чтобы идеально выбрать страницу для замещения (например, «чистый» LRU с программным ведением списков на каждый доступ). В итоге мы экономим 1 миллисекунду на дисковом I/O, но тратим 2 миллисекунды работы CPU на сложные вычисления и поддержание структур данных. «Дорогой» алгоритм с низким PF может быть хуже «дешевого» (типа Clock) с чуть более высоким PF.

#### **В каких ситуациях стоимость page fault резко возрастает, и как это связано с I/O и состоянием dirty-страниц? ⭐⭐**
Стоимость PF возрастает, если для освобождения места нужно вытеснить **dirty (грязную)** страницу. 
*   **Clean page:** ОС просто затирает её в RAM (она уже есть на диске).
*   **Dirty page:** ОС обязана сначала записать её в swap/файл на диск, дождаться подтверждения записи, и только потом прочитать новую страницу. Это удваивает нагрузку на шину I/O.

#### **Какие компромиссы появляются при стремлении сделать подкачку “прозрачной” для процесса? ⭐⭐**
Прозрачность означает, что программист не пишет код для подгрузки данных (в отличие от оверлеев прошлого).
**Компромисс:** Непредсказуемость времени выполнения. Программа может работать молниеносно, а в следующий момент «замереть» на 10-20 мс из-за PF. Это критично для систем реального времени (hard real-time), где такая прозрачность недопустима.

#### **Почему управление памятью нельзя полностью “свести к выбору FIFO/LRU”? ⭐**
Потому что алгоритм замещения — это лишь часть стратегии. Нужно также решать:
1.  **Сколько** кадров дать каждому процессу (аллокация).
2.  **Когда** подкачивать (префетчинг).
3.  **Кого** выгружать целиком (свопинг процессов) при перегрузке.
Чистый LRU не учитывает приоритеты процессов и общие системные цели.

#### **Какие ресурсы ОС расходуются на виртуальную память помимо самой RAM (структуры данных, swap, CPU-время)? ⭐⭐**
1.  **Swap-пространство:** Место на диске.
2.  **Таблицы страниц (Page Tables):** Могут занимать десятки мегабайт RAM.
3.  **CPU-время:** На обработку исключений (traps), обновление битов доступа/изменения, поиск в таблицах.
4.  **TLB-записи:** Ограниченный ресурс кэша процессора.

#### **Как бы вы объяснили человеку без ОС-бэкграунда, почему память “заканчивается”, даже если на диске много места? ⭐⭐**
Представьте, что RAM — это ваш рабочий стол, а диск — это огромный архив в подвале. Чтобы работать с документом, вы *обязаны* положить его на стол. Если на столе нет места даже для одной бумажки, вы не можете работать, сколько бы места ни было в подвале. «Память закончилась» — значит, стол завален так плотно, что вы только и делаете, что бегаете в подвал и обратно, не успевая прочитать ни строчки.

#### **Сформулируйте ключевую разницу между локальной и глобальной политикой замещения страниц. ⭐**
*   **Локальная:** Процесс при ошибке страницы может выбрать жертву только среди *своих* страниц. Его «бюджет» кадров фиксирован или меняется медленно.
*   **Глобальная:** Процесс может забрать кадр у *любого* другого процесса. Все физические кадры — общая очередь.

#### **Почему локальная политика обеспечивает изоляцию процессов, и какой ценой? ⭐⭐**
**Изоляция:** Если процесс А начинает активно потреблять память (или плохо написан), он будет тормозить только сам себя, вызывая PF внутри своего набора кадров. Процесс Б этого не заметит.
**Цена:** Неэффективность. У процесса Б может быть много лишних (простаивающих) кадров, но процесс А не может их забрать и продолжает буксовать.

#### **Приведите сценарий, когда при локальной политике процесс будет thrashing-иться, хотя в системе есть свободная память. ⭐⭐**
Процессу выделено 10 кадров, а его «рабочее множество» (нужные сейчас данные) — 15 страниц. ОС видит, что в системе свободно еще 100 кадров, но из-за строгой локальной политики не дает их процессу. Процесс постоянно меняет свои 10 страниц туда-сюда (thrashing).

#### **Как глобальная политика может улучшить утилизацию памяти при изменяющихся нагрузках? ⭐⭐**
Она позволяет памяти «перетекать» к тем, кому она нужнее сейчас. Если компилятор закончил работу и «уснул», его кадры постепенно заберет активный браузер. Ресурсы не простаивают.

#### **Как глобальная политика может ухудшить предсказуемость производительности отдельного процесса? ⭐⭐**
Время работы процесса теперь зависит от поведения соседей. Если соседний процесс внезапно начал активно работать и вытеснил ваши страницы, ваша программа внезапно замедлится, хотя вы в ней ничего не меняли.

#### **Объясните, что означает “процессы конкурируют за кадры” в глобальной политике — на уровне последствий для latency и fairness. ⭐⭐**
Это «закон джунглей». Более активный процесс чаще обращается к памяти, его страницы выглядят «свежими» (LRU), и он захватывает всё больше кадров. Малоактивные (но важные) процессы могут быть полностью вытеснены на диск, и при попытке проснуться пользователь получит огромную задержку (latency) на подкачку всего окружения.

#### **Какие свойства системы (интерактивность, real-time, серверные нагрузки) обычно “предпочитают” локальную политику, а какие — глобальную? Обоснуйте. ⭐⭐⭐**
*   **Real-time:** Только локальная (нужна детерминированность времени отклика).
*   **Интерактивные (Desktop):** Смешанная или локальная для приоритетных окон, чтобы музыка не заикалась, когда открывается тяжелый файл.
*   **Серверные/Общие нагрузки:** Глобальная (максимальный throughput и утилизация дорогой RAM).

#### **Почему алгоритмы, основанные на рабочем множестве (Working Set, WSClock), логически “локальные”? ⭐⭐**
Потому что понятие «рабочее множество» привязано к конкретному потоку управления. Алгоритм анализирует поведение *данного* процесса за последнее время $T$, чтобы понять, сколько кадров нужно именно *ему*.

#### **FIFO и LRU могут работать в обеих политиках. Как изменится смысл “вытеснить самую старую/давно неиспользуемую” страницу при переходе от локальной к глобальной? ⭐⭐**
*   **Локальный LRU:** «Какую из страниц *этого процесса* мы не трогали дольше всего?»
*   **Глобальный LRU:** «Какую страницу *всей системы* (чья бы она ни была) не трогали дольше всего?»

#### **Какая политика лучше защищает важный системный процесс от деградации из-за шумного соседа, и как это связано с изоляцией? ⭐⭐**
Локальная политика. Она создает «песочницу» для каждого процесса. Даже если «шумный сосед» сойдет с ума и начнет требовать гигабайты памяти, системный процесс сохранит свои выделенные кадры и продолжит работу в штатном режиме.

---
