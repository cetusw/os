#### **Опишите цель и принцип работы OOM killer: почему это “крайняя мера”. ⭐⭐**
**Цель:** Предотвратить полный крах системы (kernel panic), когда свободная память и swap закончились абсолютно.
**Принцип:** ОС выбирает «наименее ценный» процесс и принудительно завершает его (SIGKILL).
**Крайняя мера:** Потому что это ведет к потере данных пользователя и нарушению работы сервисов без возможности корректного завершения.

#### **Что такое “badness score” (идеологически): какие факторы логично учитывать, чтобы выбирать жертву? ⭐⭐**
Это числовой рейтинг процесса — чем он выше, тем вероятнее процесс будет убит.
**Факторы:**
1.  **Объем памяти:** Большие процессы — приоритетные жертвы.
2.  **Время работы:** Старые процессы «жалко» убивать больше, чем новые.
3.  **Приоритет (nice):** Системные и важные процессы имеют иммунитет.
4.  **Наличие root-прав:** Обычно снижает badness.
5.  **Прямое взаимодействие с пользователем:** Не стоит убивать активное окно.

#### **Какие риски несёт OOM killer для целостности данных и пользовательского опыта? ⭐⭐**
*   **Данные:** Файлы могут остаться в промежуточном состоянии (corruption), базы данных могут потребовать долгого восстановления.
*   **Опыт:** Внезапное исчезновение браузера с 50 вкладками или IDE с несохраненным кодом крайне негативно воспринимается пользователем.

#### **В каких случаях завершение процесса лучше, чем swapping, и наоборот? ⭐⭐⭐**
*   **Завершение лучше:** Если процесс «утек» (memory leak) и бесконечно потребляет память. Свопинг его не спасет, он просто забьет диск.
*   **Swapping лучше:** Если нехватка памяти временная (пиковая нагрузка). Мы «переждем» тяжелый момент, сохранив состояние всех программ.

#### **Объясните swapping как “двухуровневое планирование”: что это означает в терминах активных/неактивных процессов. ⭐⭐**
1.  **Микро-уровень (CPU Scheduler):** Выбирает, какой из *находящихся в RAM* процессов получит квант времени.
2.  **Макро-уровень (Swapper):** Выбирает, какие процессы вообще *достойны находиться в RAM*, а какие должны подождать на диске в «замороженном» состоянии.

#### **Почему swapping может вылечить thrashing, хотя формально добавляет I/O? ⭐⭐**
Потому что он снижает конкуренцию. Вместо того чтобы 10 процессов «дрались» за память и диск одновременно, мы выгружаем 5 на диск. Оставшиеся 5 получают достаточно RAM для своих рабочих множеств, перестают генерировать PF и быстро завершают работу. Затем мы возвращаем выгруженные процессы.

#### **Как ОС может определить, какой процесс выгоднее swap out, чтобы минимально ударить по отзывчивости? ⭐⭐⭐**
1.  **Idle time:** Процессы, к которым давно не обращались.
2.  **Background vs Foreground:** Фоновые демоны — первые кандидаты.
3.  **Small Working Set:** Если процесс легко «упаковать» и «распаковать».

#### **Почему “уменьшить нагрузку на память” часто означает “уменьшить число активных процессов”, а не “улучшить алгоритм замещения”? ⭐⭐**
Потому что алгоритм замещения лишь перекладывает страницы в рамках заданного объема. Если сумма рабочих множеств больше RAM, никакой алгоритм не сотворит чуда. Поможет только физическое уменьшение спроса — т.е. остановка части потребителей.

#### **В чём разница между компактизацией, сжатием и deduplication на уровне целей и затрат? ⭐⭐**
*   **Компактизация:** Перемещение данных в RAM для устранения внешней фрагментации (цель — найти непрерывный кусок). Затраты: копирование памяти.
*   **Сжатие (ZRAM):** Сжатие страниц алгоритмами типа LZO/LZ4 прямо в RAM. Цель — уместить больше данных. Затраты: CPU.
*   **Deduplication (KSM):** Поиск одинаковых страниц и замена их одной физической. Цель — экономия на дублях. Затраты: очень много CPU на поиск.

#### **Как работает same-page merging / deduplication: какие страницы ищем, как храним, почему это экономит память? ⭐⭐**
Ядро сканирует память и считает хэши страниц. Если две страницы идентичны (например, две копии одной библиотеки в разных виртуальных машинах), ОС оставляет один физический кадр, а в таблицах страниц обоих процессов указывает на него. 
**Экономия:** Часто в облаках/VDI десятки ОС хранят одни и те же файлы кода в памяти.

#### **Почему deduplication требует механизма copy-on-write при записи, и что будет без него? ⭐⭐**
Потому что страница теперь общая. Если процесс А захочет изменить «свою» страницу, эти изменения увидит процесс Б, что недопустимо.
**Без COW:** Нарушится изоляция — вы измените текст в своем блокноте, и он изменится у соседа.

#### **Какие риски/минусы есть у deduplication (CPU overhead, задержки, безопасность/side-channel, ложные совпадения)? ⭐⭐⭐**
1.  **CPU Overhead:** Постоянное сканирование RAM нагружает процессор.
2.  **Side-channel (Безопасность):** Атакующий может замерить время записи в страницу. Если оно чуть больше (из-за срабатывания COW), значит, такая страница уже была в системе. Это позволяет красть секреты (например, ключи шифрования).

#### **Объясните Copy-on-Write на примере fork() в UNIX: что помечается Read-Only и что запускает trap. ⭐⭐**
При `fork()` ОС не копирует память родителя. Она просто копирует таблицу страниц.
1.  Все страницы помечаются в таблицах как **Read-Only**.
2.  Когда любой из процессов пытается *записать* в страницу, происходит **trap** (защита памяти).
3.  Ядро видит, что это COW-страница, копирует её в новый физический кадр, обновляет таблицу страниц и разрешает запись.

#### **Почему COW ускоряет запуск процессов и экономит память именно “в среднем”, а не всегда? ⭐⭐**
**Ускорение:** `fork()` выполняется мгновенно, не нужно копировать гигабайты.
**В среднем:** Большинство процессов после `fork()` сразу вызывают `exec()`, который полностью заменяет память. В этом случае копирование вообще не понадобилось бы.
**Не всегда:** Если после `fork()` оба процесса начнут активно писать в память, ОС все равно придется всё скопировать, плюс добавятся накладные расходы на обработку тысяч traps.

---
