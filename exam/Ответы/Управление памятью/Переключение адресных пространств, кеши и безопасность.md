#### **Почему при смене CR3 сбрасывается TLB, но не обязательно сбрасываются L1/L2/L3 кеши? ⭐⭐⭐**

Регистр **CR3** содержит физический адрес корневой таблицы страниц текущего процесса. Поскольку каждый процесс имеет свою уникальную таблицу страниц, при переключении контекста (смене CR3) старые виртуальные адреса начинают указывать на совершенно другие физические фреймы, что делает старые записи в **TLB** (кэше трансляции адресов) неверными или даже опасными. В то же время данные в **L1/L2/L3 кешах** обычно привязаны к физическим адресам (физически индексируемые кеши), поэтому содержимое самой памяти остается валидным независимо от того, какой процесс к нему обращается, если механизмы защиты это позволяют. Сброс всех уровней кеша данных при каждом переключении процесса был бы катастрофически медленным для производительности системы.

---

#### **Чем полезно то, что кеши работают по физическим адресам, и какой «неочевидный минус» это создаёт для безопасности? ⭐⭐⭐**

Использование физических адресов в кешах позволяет избегать их полной очистки при смене активного процесса, так как одни и те же данные в ОЗУ всегда имеют один и тот же физический адрес. Однако «неочевидным минусом» для безопасности является возникновение **побочных каналов (side channels)**. Поскольку кеш является общим ресурсом, один процесс может наблюдать за временем доступа к своим данным и делать выводы о том, какие адреса (и, следовательно, данные) использовал другой процесс, что ведет к возможности утечки конфиденциальной информации.

---

#### **Объясните принцип, как измерение времени доступа к данным в кеше может приводить к утечкам (на уровне идеи, без деталей конкретных атак). ⭐⭐⭐**

Идея основана на огромной разнице в скорости между **cache hit** (попаданием в кэш) и **cache miss** (обращением к оперативной памяти). Если процесс-злоумышленник замеряет время доступа к определенному фрагменту данных и видит, что оно минимально, значит, эти данные уже находятся в кэше, потому что их недавно использовал другой процесс или ядро ОС. Таким образом, через задержки памяти можно восстанавливать паттерны доступа других программ, что является основой атак типа Meltdown или Spectre.

---

#### **Почему даже «простая» операция смены CR3 может влиять на безопасность всей системы? ⭐⭐**

Смена **CR3** — это не просто обновление указателя, а активация совершенно другой карты памяти процесса. Если ОС некорректно изолирует страницы ядра или допускает ошибки в правах доступа (биты Supervisor/User) при настройке новых таблиц, пользовательский процесс может получить доступ к критическим данным системы. Кроме того, частые смены CR3 без современных механизмов оптимизации (вроде PCID) ведут к «холодному» TLB, что снижает общую устойчивость системы к атакам через временные задержки.

---

#### **Зачем нужны техники вроде PCID/ASID, барьеры спекуляции и изоляция таблиц страниц ядра, если смотреть на проблему со стороны памяти и кешей? ⭐⭐⭐**

Эти техники минимизируют накладные расходы и закрывают дыры в безопасности:

- **PCID/ASID** позволяют помечать записи в TLB идентификатором процесса, чтобы не очищать его полностью при каждой смене CR3, сохраняя высокую скорость работы.
- **Изоляция таблиц страниц ядра (KPTI)** физически разделяет карты памяти пользователя и ядра, предотвращая атаки типа Meltdown, которые пытаются спекулятивно считать данные ядра через кеш.
- **Барьеры спекуляции** (и барьеры памяти) принудительно упорядочивают операции, гарантируя, что процессор не выполнит опасную проверку данных в кеше до того, как будут проверены права доступа.

---

#### **Почему многоуровневые таблицы страниц делают трансляцию адресов слишком медленной без дополнительного ускорения? ⭐⭐**

При использовании многоуровневых таблиц (например, 4 уровня в x86-64) процессору для каждого (!) обращения к данным необходимо сначала выполнить 4 последовательных чтения из оперативной памяти, чтобы «пройти» по дереву таблиц и найти финальный физический адрес. Это увеличивает задержку доступа к памяти в несколько раз, превращая быстрый процессор в крайне медленный из-за постоянного ожидания ответов от шины памяти.

---

#### **Что именно кэширует TLB и почему это «кэш другого типа», чем L1/L2 для данных? ⭐⭐**

**TLB** (Translation Lookaside Buffer) кэширует не сами данные или инструкции, а **результаты преобразования** виртуальных адресов страниц в номера физических фреймов. Это «другой тип» кэша, потому что он работает не с содержимым памяти, а со служебной информацией из таблиц страниц, и обращение к нему происходит **до** того, как процессор сможет обратиться к L1/L2 кешам за самими данными.

---

#### **Объясните разницу между TLB hit и TLB miss и их влияние на латентность каждого обращения к памяти. ⭐⭐**

- **TLB hit:** нужное соответствие найдено в кэше, трансляция происходит за 1–2 такта процессора, что практически незаметно.
- **TLB miss:** соответствия нет, и MMU вынужден выполнять медленный «обход таблиц» (page walk) в оперативной памяти, что может стоить сотни тактов. Разница в латентности между попаданием и промахом TLB составляет порядка двух порядков, что делает эффективность TLB критическим фактором для скорости работы программ.

---

#### **Как устройство TLB как ассоциативного кеша влияет на скорость поиска и на стоимость промахов? ⭐⭐⭐**

TLB реализован как **ассоциативный кеш**, что позволяет выполнять поиск по всем его записям параллельно и мгновенно (за один такт). Однако из-за высокой сложности и стоимости такой аппаратуры размер TLB ограничен (от 16 до нескольких сотен записей). Небольшой размер повышает вероятность промахов при работе с большими объемами данных, а стоимость каждого промаха велика из-за необходимости последовательного чтения многоуровневых таблиц в ОЗУ.

---

#### **Зачем разделять TLB для инструкций и данных (ITLB/DTLB), и какие преимущества/сложности это даёт? ⭐⭐**

Разделение на **ITLB** (инструкции) и **DTLB** (данные) позволяет процессору одновременно транслировать адрес следующей команды и адрес операнда для текущей команды, не создавая конфликтов на входе в MMU. Преимущество — повышение параллелизма и снижение частоты промахов, так как паттерны обращения к коду и данным обычно сильно различаются. Сложность заключается в необходимости дублирования аппаратной логики и поддержки согласованности, если программа модифицирует свой код «на лету».

---

#### **Какие факторы в программе увеличивают вероятность TLB miss (паттерны доступа, размер working set, размер страниц)? ⭐⭐⭐**

1. **Паттерны доступа:** случайные (random) обращения к памяти по разным адресам вместо последовательных разрушают локальность и быстро вытесняют записи из TLB.
2. **Размер working set:** если активный набор страниц (рабочее множество) программы больше, чем может вместить TLB, промахи станут постоянными (явление, аналогичное thrashing).
3. **Размер страниц:** использование маленьких страниц (4 КБ) требует больше записей в TLB для покрытия того же объема памяти; переход на «большие страницы» (Huge Pages, 2 МБ) резко снижает число промахов.

---

#### **Чем отличается hardware-managed TLB от software-managed, и почему это влияет на дизайн ядра ОС? ⭐⭐⭐**

- **Hardware-managed (x86):** процессор сам знает структуру таблиц страниц в памяти и при промахе автоматически выполняет их обход без участия ОС. Дизайн ядра проще, но структура таблиц жестко задана «железом».
- **Software-managed (MIPS, SPARC):** при промахе TLB процессор просто вызывает исключение, и ОС должна сама программно найти нужную запись в своих структурах данных и загрузить её в TLB. Это дает ОС полную гибкость в выборе формата таблиц, но требует очень эффективных и быстрых обработчиков прерываний.

---

#### **Какие преимущества даёт hardware-managed подход (например, x86) с точки зрения простоты ОС, и какие минусы возможны? ⭐⭐**

- **Преимущества:** ОС не нужно писать сложный и критичный к скорости код для обработки каждого промаха TLB; работа с виртуальной памятью становится прозрачной и стандартизованной.
- **Минусы:** ОС ограничена форматом таблиц страниц, который навязал производитель процессора; невозможны некоторые специфические оптимизации управления памятью, которые могли бы быть полезны в узких сценариях.

---

#### **Какие преимущества даёт software-managed подход (например, MIPS/SPARC) для контроля и оптимизаций ОС? ⭐⭐⭐**

ОС получает полный контроль над управлением TLB: она может использовать любые структуры данных (хеш-таблицы, деревья, инвертированные таблицы) и применять свои политики вытеснения записей из кэша трансляции. Это позволяет реализовать более умные алгоритмы предсказания нужных страниц и более эффективно поддерживать огромные адресные пространства.

---

#### **Почему после заполнения TLB команда «повторяется», и какие свойства архитектуры делают это корректным? ⭐⭐⭐**

Повтор инструкции необходим, так как в момент первого исполнения адреса не могли быть транслированы, и команда не была завершена (произошел trap или fault). Архитектура обеспечивает это через сохранение точного состояния регистров и счетчика команд (PC) в момент сбоя. После того как ОС или MMU заполнили TLB, процессор возвращается к сохраненному PC и выполняет ту же команду заново, на этот раз успешно проходя этап трансляции адреса.

---
