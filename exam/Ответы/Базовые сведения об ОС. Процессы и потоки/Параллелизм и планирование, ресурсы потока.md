#### **Чем псевдопараллелизм на одном CPU отличается от реального параллелизма на многоядерной системе? ⭐**:

Разница заключается в физической возможности одновременного исполнения инструкций:

- **Псевдопараллелизм** возникает на системах с **одним ядром**, где ОС быстро переключает процессор между процессами (каждые десятки или сотни миллисекунд). Это создает у пользователя **иллюзию одновременности**, хотя в каждый конкретный момент времени выполняется только одна задача.
- **Реальный параллелизм** возможен на **многопроцессорных или многоядерных системах**, где два или более потока могут выполняться **физически одновременно** на разных ядрах.

---

#### **Как ОС решает, какой поток получит CPU следующим (в общих чертах)? ⭐⭐**:

За этот выбор отвечает специальная часть ОС — **планировщик (scheduler)**, использующий определенные алгоритмы планирования. Решение принимается в моменты создания/завершения процессов, их блокировки на I/O или по прерыванию таймера. **Общие критерии выбора:**

- **Справедливость:** предоставление каждому потоку равной доли ресурсов.
- **Приоритетность:** выполнение более важных задач (например, системных служб или интерактивных приложений) в первую очередь.
- **Эффективность:** минимизация времени простоя CPU и количества переключений контекста.

---

#### **Что означают состояния running/ready/blocked/terminated для потока, и как они соотносятся с состояниями процессов? ⭐⭐**:

Состояния потоков практически идентичны состояниям процессов, так как поток является основной единицей планирования.

1. **Running (Выполняется):** поток фактически использует процессор в данный момент.
2. **Ready (Готов):** поток готов к работе, но временно остановлен, чтобы дать поработать другому потоку; он ждет своей очереди от планировщика.
3. **Blocked (Заблокирован):** поток ожидает внешнего события (например, завершения чтения с диска или сигнала), не претендуя на CPU.
4. **Terminated (Завершен):** поток закончил выполнение, но его ресурсы могут быть еще не полностью очищены ОС.

---

#### **Приведите пример перехода thread: running → blocked и объясните, почему это не «ошибка планировщика». ⭐⭐**:

Типичный пример — системный вызов **чтения данных из файла (`read`)**. Когда поток запрашивает данные с медленного устройства (HDD/SSD), он не может продолжать вычисления, пока данные не окажутся в памяти. Это **не ошибка планировщика**, а **эффективное управление ресурсами**: вместо того чтобы CPU простаивал в пустом ожидании, планировщик переводит текущий поток в состояние _Blocked_ и отдает процессор другому готовому потоку (_Ready_), повышая общую загрузку системы.

---

#### **В каких ситуации полезен добровольный yield, и почему он не гарантирует немедленного переключения? ⭐⭐**:

Добровольная уступка процессора (`yield`) полезна:

- В системах с **кооперативной многозадачностью** (например, пользовательские потоки), где нет принудительного вытеснения по таймеру.
- Когда поток завершил важную фазу работы и хочет дать шанс другим «джентльменским» способом.

Это **не гарантирует переключения**, так как если в очереди _Ready_ нет других потоков или текущий поток имеет самый высокий приоритет, планировщик может снова выбрать его для продолжения работы.

---

#### **Какие метрики/сигналы в системе вы бы смотрели, чтобы понять: приложение ограничено CPU или I/O? ⭐⭐⭐**:

- **CPU-bound (ограничено процессором):** характеризуется длинными вычислительными всплесками (**CPU burst**). В `top` или `htop` это проявляется высоким процентом использования CPU (`%us`, `%sy`) и низким временем ожидания ввода-вывода (`%wa`).
- **I/O-bound (ограничено вводом-выводом):** характеризуется короткими вычислениями и частыми блокировками. Главный сигнал — высокий **Load Average** при относительно низком использовании CPU, а также высокие показатели в колонке **`wa` (I/O wait)** или большое количество процессов в состоянии **`D` (Uninterruptible sleep)** в Linux.

---

#### **Почему у каждого потока должен быть собственный стек? Что сломается при «общем стеке»? ⭐⭐**:

Потоки одного процесса разделяют общую память, но каждый из них выполняет свою функцию с собственным набором вызовов. **Собственный стек необходим**, чтобы хранить **кадры процедур**: локальные переменные и адреса возврата. При «общем стеке» возникнет хаос: если два потока одновременно вызовут разные функции, их данные на стеке перемешаются, и при возврате из функции поток прыгнет по адресу, записанному «соседом», что приведет к немедленному краху программы.

---

#### **Что такое «кадры стека» и почему их структура важна для понимания выполнения потока? ⭐**:

**Кадр стека (stack frame)** — это блок данных на стеке, создаваемый при каждом вызове процедуры. Он содержит входные параметры, локальные переменные и временные данные, которые не поместились в регистры. Структура кадров важна, так как она определяет **контекст выполнения**: кто вызвал функцию и куда нужно вернуть управление после её завершения.

---

#### **Какие данные разделяются потоками в куче/глобальной области, а какие — «живут» на стеке каждого потока? ⭐⭐**:

- **Разделяемые (общие) ресурсы:** глобальные переменные, динамическая память (**куча**), открытые файлы, сигналы и таймеры.
- **Индивидуальные ресурсы (на стеке):** локальные переменные функции, параметры вызова, адреса возврата, а также состояние регистров и счетчик команд (PC).

---

#### **Приведите пример ошибки, когда адрес локальной переменной передают в поток, и объясните причину. ⭐⭐**:

**Пример:** Главный поток создает локальную переменную внутри функции, передает её адрес в новый поток через `pthread_create` и завершает свою функцию. **Причина ошибки:** Локальная переменная живет на стеке создавшего её потока. Как только функция в главном потоке завершается, её кадр стека считается свободным и может быть затерт другими данными. Когда новый поток попытается прочитать данные по этому адресу, он получит **«мусор» или вызовет ошибку доступа**, так как память больше не валидна.

---

#### **Как различается типичная отладка багов «повреждение стека» vs «гонка данных» (на уровне симптомов)? ⭐⭐⭐**:

- **Повреждение стека (stack corruption):** обычно приводит к **немедленному и стабильному краху** (Segmentation fault) при попытке возврата из функции или к странному изменению локальных переменных.
- **Гонка данных (race condition):** симптомы крайне нестабильны и зависят от порядка исполнения (тайминга). Система может работать корректно в 99% случаев, но иногда выдавать **неверный результат** (например, неправильное значение счетчика) без падения самой программы. Такие баги очень трудно воспроизвести и отладить.

---

#### **Что означает «ядро не в курсе потоков» в user-level модели, и как библиотека переключает потоки? ⭐⭐**:

В модели потоков на уровне пользователя (**user-level threads**) ядро ОС видит только **один процесс** и планирует время именно для него. Библиотека потоков ведет собственную **таблицу потоков** внутри адресного пространства процесса. Переключение происходит полностью в пользовательском пространстве: библиотека сохраняет регистры текущего потока и загружает регистры другого. Это происходит очень быстро, так как не требуется системный вызов и переход в режим ядра.

---

#### **Почему блокирующий системный вызов (например, read) блокирует весь процесс при user-level threads? ⭐⭐**:

Поскольку ядро не знает о существовании нескольких потоков внутри процесса, оно воспринимает любой запрос как исходящий от всего процесса целиком. Когда один поток вызывает блокирующий `read`, ядро переводит **весь процесс** в состояние _Blocked_ до завершения операции, замораживая выполнение всех остальных потоков в этом процессе, даже если они готовы работать.

---

#### **Почему page fault в user-level модели может «заморозить» все user threads, даже если они логически независимы? ⭐⭐⭐**:

Ситуация аналогична блокирующему I/O: когда поток обращается к адресу, которого нет в RAM, происходит **page fault**. Ядро приостанавливает выполнение **всего процесса**, чтобы подгрузить страницу с диска. Поскольку планировщик библиотеки потоков работает _внутри_ этого процесса, он тоже останавливается, и никакие другие пользовательские потоки не могут получить управление, пока процесс заблокирован ядром.

---

#### **Какие обходные решения позволяют делать user-level потоки практичнее (select/poll/epoll, wrapper’ы), и чем они платят? ⭐⭐⭐**:

Для минимизации блокировок используются:

- **Неблокирующий ввод-вывод** и вызовы типа `select/poll/epoll`, которые позволяют проверить, готовы ли данные, прежде чем вызывать блокирующий `read`.
- **Wrapper'ы (обёртки):** системные библиотеки заменяют стандартные вызовы своими версиями, которые сначала проверяют возможность выполнения без блокировки.
- **Плата:** значительное усложнение кода библиотеки, дополнительные накладные расходы на постоянные проверки и потеря чистой семантики блокирующих вызовов.

---

#### **В чём ключевые преимущества kernel threads над user-level threads, и какие накладные расходы они добавляют? ⭐⭐**:

- **Преимущества:** реальный параллелизм на многоядерных системах, отсутствие блокировки всего процесса при блокировке одного потока или page fault.
- **Расходы:** создание, уничтожение и переключение потоков требуют **системных вызовов**, что значительно дороже (в 10–100 раз медленнее), чем операции в пользовательском пространстве.

---

#### **Объясните гибридную модель M:N: что планирует ОС, что планирует рантайм, и почему это похоже на goroutines/виртуальные потоки. ⭐⭐⭐**:

В модели **M:N** («много-ко-многим») пользовательские потоки мультиплексируются на потоки ядра.

- **Ядро ОС** планирует и управляет небольшим числом **kernel threads**, обеспечивая параллелизм на ядрах процессора.
- **Рантайм (библиотека)** планирует большое количество **user threads** поверх этих ядерных потоков. Это похоже на **goroutines (Go)** или **виртуальные потоки (Java Loom)**: система получает легкость и масштабируемость пользовательских потоков (их могут быть сотни тысяч), сохраняя при этом надежность и параллелизм потоков ядра.