#### **В каких случаях оправдан std::recursive_mutex, и почему его часто считают «запахом дизайна»? ⭐⭐⭐**:

Использование **`std::recursive_mutex`** оправдано в ситуациях, когда один и тот же поток должен иметь возможность повторно захватить один и тот же мьютекс без возникновения дедлока. Это часто встречается в рекурсивных алгоритмах или в сложных классах, где один публичный метод, захватывающий блокировку, вызывает другой публичный метод того же объекта, который также пытается её захватить.

**Почему это «запах дизайна»:**

1. **Сложность отладки:** Рекурсивные блокировки маскируют ошибки в логике программы. Если коду требуется рекурсивный мьютекс, это часто означает, что обязанности по управлению ресурсами внутри класса распределены нечетко.
2. **Нарушение инвариантов:** Когда поток повторно заходит в критическую секцию, данные могут находиться в промежуточном, несогласованном состоянии, так как первая («внешняя») операция еще не завершена.
3. **Производительность:** Проверка владельца потока при каждом захвате делает `recursive_mutex` медленнее обычного `std::mutex`.

---

#### **Чем полезны std::timed_mutex и таймауты в синхронизации? Приведите пример. ⭐⭐⭐**:

**`std::timed_mutex`** расширяет функционал обычного мьютекса методами `try_lock_for` и `try_lock_until`,. Это позволяет потоку пытаться захватить замок в течение определенного времени, а не блокироваться вечно.

**Польза:**

- **Предотвращение зависаний:** Если ресурс занят слишком долго (возможно, из-за ошибки в другом потоке), поток может отказаться от ожидания и выполнить альтернативный код.
- **Улучшение отзывчивости (Latency):** В интерактивных приложениях поток UI может попытаться взять данные и, если не успел за 10 мс, просто отрисовать старое состояние вместо «замирания».

**Пример:** В сетевом сервере поток пытается захватить лог-файл для записи. Если файл заблокирован другим потоком более 1 секунды, сервер может сбросить ошибку в консоль или буферизировать сообщение в памяти, чтобы не задерживать обработку клиентских запросов.

---

#### **Почему RAII-обёртки (lock_guard/unique_lock) уменьшают вероятность дедлоков и утечек блокировки? ⭐⭐**:

Эти обертки реализуют принцип **RAII** (получение ресурса есть инициализация): замок захватывается в конструкторе и **автоматически освобождается в деструкторе** при выходе объекта из области видимости.

**Преимущества:**

1. **Утечки блокировки:** Даже если внутри критической секции возникнет исключение (exception) или сработает `return`, деструктор обертки все равно будет вызван, и мьютекс будет разблокирован. Без RAII программист может забыть вызвать `unlock()`, что приведет к вечной блокировке всех остальных потоков.
2. **Надежность:** Код становится чище и менее подвержен ошибкам, так как управление состоянием замка привязано к времени жизни переменной в стеке.

---

#### **Какие риски возникают, если внутри критической секции делать I/O или ждать другие ресурсы? ⭐⭐**:

Длительные операции внутри критической секции — одна из главных причин деградации производительности. **Риски:**

1. **Конкуренция (Contention):** Другие потоки будут простаивать в ожидании, пока завершится медленный ввод-вывод (чтение диска или сетевой запрос).
2. **Инверсия приоритетов:** Высокоприоритетный поток может заблокироваться на мьютексе, ожидая низкоприоритетный поток, который «уснул», выполняя I/O внутри секции.
3. **Дедлоки:** Если внутри одной критической секции поток пытается захватить другой ресурс (например, другой мьютекс), риск возникновения циклического ожидания возрастает многократно.

---

#### **Какие способы избежать дедлоков при захвате нескольких мьютексов? ⭐⭐⭐**:

1. **Lock Ordering (Иерархия замков):** Установление строгого порядка захвата ресурсов. Все потоки должны захватывать мьютексы в одной и той же последовательности (например, сначала А, потом Б).
2. **std::lock (C++11):** Специальная функция, которая может атомарно захватить несколько мьютексов сразу, используя алгоритмы предотвращения дедлоков «под капотом».
3. **Try-lock loop:** Поток пытается захватить первый мьютекс, а затем использует `try_lock()` для остальных. Если какой-то замок занят, поток освобождает **все** уже захваченные мьютексы, делает паузу (`yield`) и пробует заново.

---

#### **Чем std::shared_mutex принципиально отличается от обычного std::mutex по модели допуска потоков? ⭐⭐**:

**`std::shared_mutex`** (C++17) реализует модель **«много читателей — один писатель»**.

- **Shared lock (совместный):** Позволяет **нескольким** потокам одновременно удерживать блокировку для чтения данных.
- **Exclusive lock (эксклюзивный):** Позволяет только **одному** потоку владеть блокировкой для записи, при этом доступ для всех читателей закрывается. Обычный `std::mutex` всегда предоставляет только эксклюзивный доступ: один зашел — все остальные (и читатели, и писатели) ждут.

---

#### **В каких сценариях std::shared_mutex реально ускоряет систему, а в каких может замедлить? ⭐⭐**:

- **Ускоряет:** Когда операции **чтения происходят значительно чаще**, чем записи (сценарий Read-Mostly), и критические секции кратковременны,. Например, при поиске в справочнике или кэше.
- **Замедляет:** Если записи происходят часто или если количество ядер процессора невелико. Накладные расходы на поддержание счетчика активных читателей и управление сложной очередью ожидания делают `shared_mutex` тяжелее обычного мьютекса,.

---

#### **Почему стандарт не гарантирует справедливость в std::shared_mutex и к чему это приводит для писателей? ⭐⭐⭐**:

Стандарт не навязывает конкретную политику приоритетов, оставляя её на усмотрение реализации ОС (через механизмы вроде `pthread_rwlock` или `SRWLock`).

**Последствия для писателей:** Это приводит к **голоданию писателей (writer starvation)**. Если поток читателей непрерывен (новые читатели приходят до того, как ушли старые), писатель может никогда не получить эксклюзивный доступ, так как мьютекс всегда будет находиться в «совместном» состоянии. Для решения этой проблемы часто проектируют кастомные «честные» замки (**FairRWLock**), которые блокируют новых читателей, если в очереди есть ожидающий писатель.

---

#### **Почему upgrade (shared → unique) небезопасен без выхода? Опишите гонку. ⭐⭐⭐**:

В C++ нет встроенной поддержки безопасного «апгрейда» блокировки (перехода от `shared_lock` к `unique_lock` без освобождения первого).

**Сценарий дедлока при «наивном апгрейде»:**

1. Два потока (А и Б) одновременно держат `shared_lock` (читают данные).
2. Оба решают, что данные нужно обновить, и пытаются «апгрейднуться» до `unique_lock`.
3. Поток А ждет, пока Поток Б отпустит свой `shared_lock`.
4. Поток Б ждет, пока Поток А отпустит свой `shared_lock`.
5. **Итог:** Ни один не может продвинуться — возник дедлок. Единственный безопасный путь — освободить замок для чтения и захватить его заново для записи.

---

#### **Почему shared_mutex подходит только для коротких критических секций, несмотря на «параллельность чтения»? ⭐⭐**:

Несмотря на возможность параллельного чтения, `shared_mutex` остается примитивом синхронизации, управляемым ядром (через **futex** в Linux). Длительное удержание даже «разделяемого» замка блокирует поток-писатель, что в конечном итоге вызывает заторы во всей системе. Если чтение занимает очень много времени, лучше использовать механизмы без блокировок, такие как **RCU (Read-Copy-Update)**, где читатели вообще не используют замки и не блокируют писателей.