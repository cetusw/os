#### **Почему busy waiting считается проблемой в пользовательских программах? Назовите минимум 3 причины. ⭐**:

**Активное ожидание (busy waiting)** — это состояние, при котором процесс непрерывно проверяет условие в цикле, ожидая освобождения ресурса.

Это считается проблемой по следующим причинам:

1. **Бесполезная трата ресурсов CPU:** Процессор тратит такты на выполнение пустых проверок вместо того, чтобы выполнять полезную работу других потоков.
2. **Инверсия приоритетов:** Если высокоприоритетный процесс (H) начинает активное ожидание ресурса, который удерживает низкоприоритетный процесс (L), планировщик может отдавать всё время H. В результате L никогда не получит CPU, чтобы освободить ресурс, и система «зависнет».
3. **Низкая эффективность:** Активное ожидание крайне непроизводительно при длительных критических секциях, так как поток занимает ядро процессора, не совершая прогресса.

---

#### **Почему «запрет прерываний» работает как механизм взаимного исключения на одноядерной системе, и почему ломается на SMP? ⭐⭐**:

- **На одноядерной системе:** Поскольку в каждый момент времени выполняется только один процесс, запрет прерываний гарантирует, что текущий процесс не будет вытеснен планировщиком. Это делает его действия внутри критической секции фактически атомарными для системы.
- **На SMP (многопроцессорных системах):** Команда отключения прерываний действует только на тот **локальный CPU**, на котором она выполнена. Другие процессоры в системе продолжают работать и могут одновременно с первым процессом обратиться к той же общей памяти, что полностью разрушает механизм взаимного исключения.

---

#### **Чем отличается «запрет прерываний» от «атомарной инструкции с блокировкой шины/кэша» с точки зрения охвата других CPU? ⭐⭐**:

- **Запрет прерываний (CLI):** Охватывает только текущее ядро. Он предотвращает переключение контекста на данном CPU, но никак не ограничивает доступ других ядер к оперативной памяти.
- **Атомарная инструкция (например, TSL или XCHG):** Работает на уровне всей системы. Она активирует механизм «bus lock» (блокировку шины) или протоколы когерентности кэша, физически запрещая всем остальным процессорам доступ к конкретной ячейке памяти до завершения операции «чтение-модификация-запись».

---

#### **Почему инструкции CLI/STI недоступны в ring 3 и что произойдёт при попытке выполнить их в user mode? ⭐⭐**:

Инструкции управления прерываниями являются **привилегированными**, так как позволяют напрямую влиять на работу аппаратного обеспечения.

- **Причина:** Если дать пользовательскому процессу (Ring 3) право отключать прерывания, он сможет захватить процессор навсегда, заблокировав работу всей операционной системы.
- **Результат:** При попытке выполнить `CLI` или `STI` в пользовательском режиме процессор сгенерирует исключение **General Protection Fault (#GP)**, и ОС, скорее всего, принудительно завершит программу.

---

#### **В каких случаях ядро ОС всё же использует отключение прерываний, и почему время удержания должно быть «считанные инструкции»? ⭐⭐⭐**:

Ядро использует этот механизм для защиты критических структур данных самого ядра (например, очередей планировщика).

- **Примеры:** Обновление списка готовых к работе процессов или обработка системного таймера.
- **Почему краткость важна:** Пока прерывания отключены, система «слепа» к внешним событиям. Если держать их выключенными долго, можно пропустить сигналы от оборудования (сетевые пакеты, ввод с клавиатуры), возрастёт латентность, и система станет нестабильной или отзывчивость резко упадет.

---

#### **Почему «простая lock-переменная» не обеспечивает взаимного исключения? Опишите гонку пошагово. ⭐**:

Проблема в том, что проверка переменной и её установка не являются единым неделимым действием.

**Пошаговая гонка:**

1. **Процесс А** читает значение `lock`. Оно равно `0` (свободно).
2. В этот момент происходит прерывание таймера, и планировщик запускает **Процесс Б**.
3. **Процесс Б** читает `lock`, тоже видит `0`, записывает `1`, входит в критическую секцию.
4. Планировщик возвращает управление **Процессу А**. Тот «помнит», что видел `0`, записывает `1` и тоже входит в критическую секцию. **Итог:** Два процесса одновременно работают с защищенным ресурсом.

---

#### **Почему «прочитать lock дважды» не решает проблему? Сформулируйте, какая именно гарантия отсутствует. ⭐**:

Двойная проверка не помогает, потому что переключение контекста может произойти между любым чтением и последующей записью. Даже если прочитать `0` сто раз, в сто первый раз (перед самой записью `1`) другой процесс может успеть занять ресурс. **Отсутствующая гарантия:** **Атомарность** операции «проверить и установить» (test-and-set).

---

#### **Что такое Strict Alternation и в чём его ключевой дефект с точки зрения требований к критической секции? ⭐⭐**:

**Строгое чередование (Strict Alternation)** — это программный алгоритм, где процессы входят в критическую секцию строго по очереди (0, потом 1, потом снова 0) на основе переменной `turn`.

**Ключевой дефект:** Он нарушает одно из фундаментальных условий корректной синхронизации — процесс, находящийся **вне критической секции**, не должен блокировать другие процессы.

---

#### **Приведите сценарий, где Strict Alternation блокирует процесс, хотя критическая секция свободна. Почему это плохо для производительности? ⭐⭐**:

**Сценарий:**

1. `turn = 0`. **Процесс 0** входит в секцию, выходит и ставит `turn = 1`.
2. **Процесс 0** быстро завершает свою некритическую работу и снова хочет в секцию.
3. Однако **Процесс 1** очень медленный или вообще занят другой задачей вне своей критической секции.
4. **Процесс 0** будет бесконечно крутиться в цикле, ожидая, пока `turn` станет `0`, хотя сама критическая секция в это время пуста. **Для производительности:** Это катастрофично, так как процессорное время тратится на ожидание простаивающего ресурса.

---

#### **Можно ли «починить» Strict Alternation без аппаратной атомарности? Если да — какой ценой; если нет — почему? ⭐⭐⭐**:

Логически — **да**, это решается алгоритмами вроде **Петерсона** или **Деккера**, которые используют массив флагов `interested` для фиксации намерения войти.

Однако на практике (на современных CPU) «починить» это полностью без аппаратной поддержки **нельзя**. Цена программного решения без атомарных примитивов на SMP-системах — это необходимость в **барьерах памяти (memory fences)**, так как современные процессоры переупорядочивают инструкции, что ломает логику алгоритмов даже при их теоретической верности.

---

#### **Объясните идею алгоритма Петерсона: зачем нужны interested[] и turn одновременно? ⭐⭐**:

Это элегантное решение, сочетающее две идеи:

1. **Массив `interested[i]`:** Каждый процесс использует свой флаг, чтобы заявить: «Я хочу войти в критическую секцию». Это предотвращает ситуацию, когда процесс входит в пустую секцию, не учитывая соседа.
2. **Переменная `turn`:** Служит «арбитром» на случай, если оба процесса заявят о своем интересе одновременно. Она определяет, чей ход сейчас. Последний, кто записал свое значение в `turn`, «уступает» дорогу другому.

---

#### **Докажите (словами) хотя бы одно свойство: mutual exclusion / progress / bounded waiting для алгоритма Петерсона. ⭐⭐⭐**:

**Доказательство Mutual Exclusion (Взаимного исключения):** Предположим, оба процесса вошли в критическую секцию. Значит, оба увидели в `while` условие ложным. Для Процесса 0 это возможно, только если `interested == false` ИЛИ `turn == 1`. Если оба процесса заинтересованы (`interested=true, interested=true`), то условие выхода из цикла зависит только от `turn`. Но `turn` — это одна ячейка памяти, она не может быть одновременно равна 0 и 1. Тот процесс, который записал в `turn` последним, останется ждать в цикле, а другой войдет. Таким образом, двое войти не могут.

---

#### **Почему реализация Петерсона на обычных bool/int может ломаться на современных CPU? ⭐⭐⭐**:

Из-за двух аппаратных оптимизаций:

1. **Внеочередное выполнение (Out-of-order execution):** Процессор может поменять местами запись в `interested` и чтение `turn`, если посчитает их независимыми, что нарушит логическую последовательность алгоритма.
2. **Эффекты кэширования:** Запись флага одним ядром может быть видна другому ядру с задержкой, если не используются инструкции синхронизации кэша.

---

#### **Почему добавление volatile всё равно может не исправить Петерсона в C++? Что именно volatile гарантирует и чего не гарантирует? ⭐⭐⭐**:

- **Гарантирует:** `volatile` сообщает компилятору, что переменную нельзя кэшировать в регистре и каждое обращение должно идти в память.
- **НЕ гарантирует:** Он не обеспечивает **атомарности** (операция может быть прервана) и, самое главное, не создает **барьеров памяти (fences)**. Процессор всё равно сможет переупорядочить инструкции, и «гонка» останется.

---

#### **Как корректно реализовать Петерсона в C++ с std::atomic? Какие memory order’ы уместны и почему? ⭐⭐⭐**:

Для корректной работы нужно заменить `bool/int` на `std::atomic<bool>` и `std::atomic<int>`.

**Memory orders:**

- Самый безопасный вариант — стандартный **`memory_order_seq_cst`** (последовательная согласованность), который гарантирует глобальный порядок всех операций.
- Минимально необходимые — связки **Acquire/Release**. Установка флага интереса должна быть **Release** (чтобы все действия _до_ этого стали видны другим), а проверка состояния соседа — **Acquire** (чтобы увидеть его актуальные данные). Однако для алгоритма Петерсона из-за специфики «Store-Load» (запись в свой флаг и немедленное чтение чужого) обычно требуется полная последовательная согласованность или явные барьеры `atomic_thread_fence`.