#### **Как ОС управляет памятью при одновременной работе нескольких программ? Какие цели преследуются (справедливость/защита/безопасность)? ⭐⭐**:

В современных системах операционная система выступает в роли менеджера ресурсов, разделяя ограниченный объем оперативной памяти (RAM) между несколькими конкурирующими процессами.

**Основные механизмы управления:**

- **Разделение в пространстве:** ОС выделяет каждому процессу свою часть адресного пространства, чтобы несколько программ могли находиться в памяти одновременно.
- **Использование адресных пространств:** ОС создает абстракцию адресного пространства — набор адресов, к которым может обращаться процесс. Это гарантирует, что адрес `28` в одной программе физически не совпадает с адресом `28` в другой.
- **Релокация и защита:** ОС использует аппаратные средства (например, регистры базы и границы) для динамического сопоставления адресов программы с реальными физическими адресами в памяти.

**Цели управления памятью:**

1. **Защита:** Гарантия того, что процесс не сможет прочитать или изменить данные другого процесса или самой ОС. Ошибка в одной программе не должна приводить к краху всей системы.
2. **Справедливость:** Упорядоченное распределение ресурсов так, чтобы каждый процесс получал необходимый объем памяти для работы.
3. **Безопасность:** Изоляция адресных пространств предотвращает несанкционированный доступ к конфиденциальным данным других пользователей.

---

#### **Что такое виртуальная память и зачем она нужна? Опишите идею «RAM как кэш для диска/SSD». ⭐⭐**:

**Виртуальная память** — это техника, позволяющая программам работать с объемом памяти, превышающим физический объем установленной в компьютере RAM. Пространство программы делится на небольшие части — **страницы**.

**Зачем она нужна:**

- Позволяет запускать программы, размер которых больше физической памяти.
- Упрощает программирование, предоставляя приложению иллюзию непрерывного и чистого адресного пространства.
- Обеспечивает эффективную многозадачность: в памяти остаются только активные части программ.

**Идея «RAM как кэш для внешнего хранилища»:** Физическая память (RAM) в этой модели выступает в качестве быстрого буфера (кэша) для хранения наиболее часто используемых фрагментов программ и данных, основные копии которых находятся на медленном, но емком носителе (HDD или SSD).

```
+-----------------------+
|  Виртуальная память   | (Иллюзия для процесса)
+-----------+-----------+
            |
    [ Активные страницы ] ----> [ Быстрая RAM ] (Кэш)
            |
    [ Пассивные страницы] ----> [ Медленный SSD/HDD ] (Основное хранилище)
```

ОС динамически подгружает нужные страницы в RAM и выгружает неиспользуемые обратно на диск (процесс подкачки).

---

#### **Какова роль MMU? Что означает «преобразование виртуальных адресов в физические»? ⭐⭐⭐**:

**MMU (Memory Management Unit)** — это специализированный аппаратный блок (обычно встроенный в процессор), который отвечает за трансляцию адресов «на лету».

**Роль MMU:**

1. **Преобразование (Трансляция):** Перевод виртуального адреса, сгенерированного процессором, в реальный физический адрес на шине памяти.
2. **Защита:** Проверка прав доступа к странице (чтение, запись, выполнение).
3. **Обработка промахов:** Если нужной страницы нет в памяти, MMU вызывает аппаратное прерывание — **page fault**, передавая управление ОС для подгрузки данных с диска.

**Суть преобразования:** Виртуальный адрес делится на **номер страницы** и **смещение**. MMU использует номер страницы как индекс в **таблице страниц**, чтобы найти соответствующий номер физического фрейма.

**Схема работы:**

```
Виртуальный адрес: [ Номер страницы | Смещение ]
                            |             |
                     (Таблица страниц)    |
                            |             |
Физический адрес:  [  Номер фрейма  | Смещение ]
```

Смещение копируется напрямую, так как оно указывает на конкретный байт внутри страницы.

---

#### **Что такое кэш CPU (L1/L2/L3)? Объясните термины cache hit и cache miss и влияние на производительность. ⭐⭐**:

**Кэш-память** — это очень быстрая и дорогая память небольшого объема, расположенная внутри или вплотную к ядру процессора, предназначенная для хранения копий наиболее часто используемых данных из основной памяти.

**Уровни кэша:**

1. **L1:** Самый быстрый и маленький (~32 КБ), находится непосредственно в ядре. Часто разделен на кэш инструкций и кэш данных.
2. **L2:** Больше (несколько МБ) и чуть медленнее, может быть индивидуальным для каждого ядра или общим.
3. **L3:** Самый большой (десятки МБ) и медленный среди кэшей, обычно общий для всех ядер процессора.

**Основные термины:**

- **Cache hit (Попадание):** Процессор запрашивает данные, и они обнаруживаются в кэше. Доступ занимает всего 1–8 тактов (наносекунд).
- **Cache miss (Промах):** Данных в кэше нет. Процессору приходится обращаться к основной RAM, что влечет огромную задержку (штраф) в десятки и сотни циклов.

**Влияние на производительность:** Разница в скорости между L1 и RAM может составлять порядки. Эффективное использование кэша критически важно, так как промахи заставляют мощный процессор простаивать в ожидании данных из «медленной» памяти.

---

#### **Приведите примеры кэширования в ОС (не в железе) и объясните, почему это ускоряет систему. ⭐⭐**:

ОС использует принципы кэширования на программном уровне для минимизации обращений к медленным устройствам ввода-вывода (дискам).

**Примеры в ОС:**

1. **Буферный кэш файлов (Page Cache):** ОС хранит блоки недавно прочитанных или записанных файлов в оперативной памяти. Если программа снова запрашивает тот же файл, данные берутся из RAM, что в тысячи раз быстрее чтения с диска.
2. **Кэширование путей (Name Cache):** ОС сохраняет результаты преобразования длинных путей файлов (например, `/home/user/data.txt`) в адреса их дескрипторов (i-node) на диске, чтобы избежать повторного сканирования структуры каталогов.
3. **Кэширование сетевых адресов (DNS Cache):** Результат преобразования URL в IP-адрес сохраняется для будущих запросов.

**Почему это ускоряет систему:** Кэширование использует принцип **локальности обращений**: данные, к которым обращались недавно, с высокой вероятностью понадобятся снова. Программное кэширование заменяет миллионы медленных дисковых операций быстрыми операциями в RAM.

---

#### **Сравните HDD и SSD: как устроены, почему HDD медленнее при случайном доступе, и что усложняет запись в SSD. ⭐⭐**:

**Сравнение характеристик:**

- **HDD (Hard Disk Drive):** Механическое устройство с вращающимися магнитными пластинами и подвижными головками.
- **SSD (Solid State Drive):** Электронное устройство на базе флэш-памяти, не имеющее движущихся частей.

**Почему HDD медленнее при случайном доступе:** Для чтения данных в произвольном месте HDD должен физически переместить руку с головкой на нужную дорожку (**seek time**) и дождаться, пока нужный сектор пролетит под головкой (**rotational delay**). Эти механические задержки занимают миллисекунды. В SSD задержек на движение нет, поэтому доступ к любой ячейке занимает микросекунды.

**Сложность записи в SSD:** В отличие от HDD, где данные можно перезаписать поверх старых, в SSD ячейку памяти нельзя перезаписать напрямую.

1. Данные пишутся страницами, но стираются только целыми **блоками** (которые состоят из множества страниц).
2. Чтобы изменить одну страницу, нужно прочитать весь блок, стереть его и записать обратно с измененной страницей.
3. Для ускорения SSD пишет данные в новые («чистые») блоки, помечая старые как недействительные, что требует сложной **сборки мусора** и команды **TRIM**.

---

#### **Что такое «шина» в архитектуре компьютера? Почему современные системы используют несколько шин вместо одной? ⭐⭐**:

**Шина** — это общий канал связи (набор проводов или линий), по которому компоненты компьютера (CPU, память, I/O) обмениваются данными, адресами и управляющими сигналами. Ее можно сравнить с «дорогой» внутри системы.

**Почему используют несколько шин:** В ранних ПК была одна системная шина, но по мере роста скорости процессоров она стала «узким местом».

- **Разные скорости:** Современные компоненты имеют колоссальный разброс скоростей. Память (DDR) должна работать на гигантских частотах, в то время как клавиатуре достаточно низкой пропускной способности.
- **Специализация:** Использование отдельных шин (для памяти, для видеокарты PCIe, для периферии USB) позволяет устройствам не мешать друг другу и работать на своих оптимальных скоростях.
- **Иерархия:** Быстрые устройства подключаются напрямую к CPU или северному мосту, а медленные — через хабы-контроллеры.

---

#### **Чем PCIe принципиально отличается от старых параллельных общих шин (PCI/ISA)? Как масштабирование по линиям влияет на скорость? ⭐⭐⭐**:

**PCI Express (PCIe)** — это современная шина, которая радикально изменила архитектуру передачи данных по сравнению со старыми стандартами (PCI, ISA).

**Принципиальные отличия:**

1. **Последовательная vs Параллельная:** Старые шины были параллельными (например, 32 бита передавались одновременно по 32 проводам). PCIe — последовательная шина, передающая пакеты данных. Это решает проблему рассинхронизации сигналов на высоких частотах.
2. **Точка-точка vs Общая шина:** В PCI все устройства делили общие провода, и требовался арбитр для доступа. В PCIe каждое устройство имеет выделенное прямое соединение с контроллером.

**Масштабирование по линиям:** Вместо увеличения ширины параллельной шины, PCIe использует концепцию **линий (lanes)**. Каждая линия — это пара каналов для приема и передачи.

- Устройства могут использовать несколько линий одновременно: **x1, x4, x8 или x16**.
- **Влияние на скорость:** Скорость растет линейно. Например, PCIe x16 в 16 раз быстрее, чем x1. С каждым новым поколением (PCIe 4.0, 5.0, 6.0) пропускная способность одной линии удваивается. Это позволяет видеокартам (x16) получать огромную полосу пропускания, а простым картам расширения — обходиться одной линией.