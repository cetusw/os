#### **Опишите работу Round Robin и объясните роль кванта времени. Почему RR считают «простым и справедливым»? ⭐⭐**

**Round Robin (RR)** — один из старейших и простейших алгоритмов планирования, в котором каждому процессу из очереди готовых по очереди выделяется фиксированный интервал времени, называемый **квантом** (time slice). Если процесс не успевает завершиться до истечения кванта, планировщик принудительно вытесняет его и переносит в конец очереди, передавая CPU следующему.

RR считается **«простым и справедливым»**, так как его реализация требует лишь циклической очереди (FIFO), и он гарантирует, что каждый процесс получит свою долю процессорного времени в разумный срок, не позволяя одной задаче захватить ресурсы надолго.

#### **Как слишком короткий квант влияет на CPU efficiency, а слишком длинный — на response time? Почему диапазон 20–50 мс часто компромиссный? ⭐⭐**

- **Слишком короткий квант:** приводит к частым переключениям контекста, что резко снижает **эффективность CPU (efficiency)**. Поскольку на каждое переключение тратятся такты (сохранение регистров, сброс кэшей), при слишком малом кванте система будет тратить на обслуживание планировщика больше времени, чем на полезную работу.
- **Слишком длинный квант:** ухудшает **время отклика (response time)** в интерактивных системах. Если квант слишком велик, пользователю придется долго ждать своей очереди (например, реакции на нажатие клавиши), что создаёт иллюзию «зависания» системы.

Диапазон **20–50 мс** считается компромиссным, так как он достаточно велик по сравнению с временем переключения контекста (которое обычно занимает доли миллисекунды), но достаточно мал, чтобы обеспечить плавную работу интерфейса для человеческого восприятия.

#### **В каких ситуациях RR фактически становится почти невытесняющим? Свяжите это со средним CPU burst. ⭐⭐⭐**

RR становится фактически **невытесняющим**, когда **средняя длина CPU burst** процесса (время непрерывного вычисления до запроса I/O) оказывается **меньше**, чем выделенный квант времени. В этом случае процесс добровольно блокируется на операциях ввода-вывода или системных вызовах до того, как таймер успеет его прервать. Для системы это выглядит как выполнение задач в порядке очереди без принудительного вмешательства планировщика по времени.

#### **Что такое планирование по приоритетам? Какие реальные причины заставляют ОС вводить приоритеты? ⭐⭐**

**Планирование по приоритетам** — это метод, при котором каждому процессу присваивается числовой приоритет, и планировщик всегда выбирает для запуска задачу с наивысшим значением.

**Реальные причины введения приоритетов:**

1. **Разделение задач:** системные процессы или драйверы должны работать быстрее пользовательских для стабильности ОС.
2. **Интерактивность:** задачи, с которыми взаимодействует пользователь (foreground), важнее фоновых расчётов (background).
3. **Оплата ресурсов:** в облачных системах пользователи, платящие больше, могут претендовать на более высокий приоритет.
4. **Специфика нагрузки:** необходимость отдавать предпочтение I/O-зависимым задачам для баланса ресурсов.

#### **Почему приоритетные схемы могут приводить к starvation? Какие механизмы борьбы с этим используются (aging, динамика приоритета и т. п.)? ⭐⭐⭐**

**Starvation (голодание)** возникает, когда низкоприоритетные процессы бесконечно простаивают в очереди, потому что постоянно прибывают новые высокоприоритетные задачи.

**Механизмы борьбы:**

- **Aging (старение):** постепенное повышение приоритета процесса по мере того, как он долго ждет в очереди готовых.
- **Динамическая деградация:** автоматическое снижение приоритета текущего процесса после того, как он израсходовал свой квант времени, чтобы дать шанс другим.

#### **Объясните идею динамического повышения приоритета для I/O-bound процессов. Почему это улучшает общую производительность системы? ⭐⭐⭐**

Идея заключается в том, чтобы давать **I/O-bound процессам** максимально высокий приоритет, как только они завершают ожидание устройства. Поскольку такие задачи имеют очень короткие CPU bursts, они быстро выполняют свои вычисления и снова уходят на I/O.

Это улучшает **общую производительность**, так как позволяет держать устройства ввода-вывода (диски, сеть) постоянно занятыми, в то время как более длинные CPU-bound задачи «доедают» остатки процессорного времени в паузах.

#### **Почему удобно сочетать приоритеты «между классами» и round robin «внутри класса»? Какие плюсы и минусы у такого гибрида? ⭐⭐**

В такой схеме все процессы разбиты на группы (классы) по важности. Планировщик сначала ищет задачи в самом важном классе; если их несколько, они выполняются по **Round Robin**.

- **Плюсы:** гарантируется быстрое обслуживание критических задач и справедливое распределение времени между равными по важности процессами.
- **Минусы:** риск «голодания» нижних классов, если верхние классы постоянно загружены работой.

#### **Опишите идею multiple queues (многоуровневых очередей) и объясните, как они помогают одновременно интерактивным и вычислительным задачам. ⭐⭐**

Идея **многоуровневых очередей** заключается в наличии нескольких очередей с разными приоритетами и разными квантами времени.

- **Интерактивным задачам** выгодно находиться в верхних очередях с короткими квантами: они запускаются часто, что обеспечивает быстрый отклик.
- **Вычислительные задачи** (CPU-bound) постепенно «спускаются» в нижние очереди, где кванты времени намного длиннее. Это позволяет интерактивным процессам не ждать окончания долгих вычислений, а вычислительным — работать эффективно с минимумом переключений контекста.

#### **Почему увеличение кванта на нижних уровнях (1, 2, 4, 8, …) уменьшает число дорогих переключений/свапов в некоторых системах? ⭐⭐⭐**

Процессы, попавшие на нижние уровни, уже зарекомендовали себя как «тяжелые» и требующие много времени CPU. Увеличение кванта в геометрической прогрессии (например, 10 мс, 20 мс, 40 мс...) позволяет таким задачам выполнять большой объем работы за один раз. Это снижает суммарные накладные расходы на **переключение контекста** и возможный **свопинг (выгрузку на диск)**, так как процесс реже прерывается, что критично для общей пропускной способности системы.

#### **Приведите пример «обхода» политики многоуровневых очередей пользователем (например, искусственно имитировать интерактивность). Почему «правильно в теории» сложно реализовать на практике? ⭐⭐⭐**

**Пример обхода:** пользователь может написать программу, которая выполняет тяжелые вычисления, но периодически делает фиктивные операции ввода-вывода (например, короткое чтение из файла или вывод в консоль). Планировщик может ошибочно принять такой процесс за интерактивный и вернуть его в верхнюю очередь с высоким приоритетом.

На практике это сложно реализовать корректно, потому что ОС трудно отличить **реальное намерение** процесса быть отзывчивым от **манипуляции** алгоритмом без глубокого анализа поведения.

#### **Как можно адаптировать идею SJF к интерактивным системам, если длительности заранее неизвестны? Опишите подход с прогнозированием. ⭐⭐**

Идея **Shortest Job First (SJF)** в интерактивных системах реализуется через выбор процесса с кратчайшим **следующим CPU burst**. Поскольку ОС не знает будущего, она использует **прогнозирование** на основе истории прошлых запусков процесса. Алгоритм предполагает, что если процесс ранее выполнял короткие всплески активности, то и следующий его всплеск будет коротким.

#### **Объясните формулу экспоненциального сглаживания (aging) для оценки следующего CPU burst и смысл параметра (a). ⭐⭐⭐**

Формула имеет вид: **$T_{new} = a T_{old} + (1 - a) T_{measured}$**, где:

- $T_{new}$ — прогноз на следующий CPU burst.
- $T_{old}$ — предыдущий прогноз.
- $T_{measured}$ — фактически измеренная длительность последнего burst.
- **Параметр (a)** определяет «вес» истории: если $a=1/2$, то история и свежий замер важны поровну; если $a$ близко к 1, то система игнорирует случайные всплески и полагается на долгосрочный тренд.

#### **В чём идея guaranteed scheduling (примерно 1/n CPU каждому) и как измерение «получено vs положено» влияет на выбор следующего процесса? ⭐⭐**

Идея **гарантированного планирования** заключается в том, чтобы предоставить каждому из $n$ процессов ровно $1/n$ времени процессора. Система постоянно измеряет общее время жизни процесса и фактическое время, проведенное им на CPU. Затем вычисляется отношение: **фактическое время / (время жизни / n)**. Планировщик выбирает процесс с **наименьшим значением** этого отношения (то есть того, кто получил меньше всего ресурсов относительно своего «законного» обещания) и запускает его, пока отношение не превысит показатели соседа.

#### **Объясните основную идею Linux CFS на концептуальном уровне: что такое «spent execution time», зачем дерево, почему выбирают «самого недополучившего». ⭐⭐⭐**

**CFS (Completely Fair Scheduler)** реализует идею гарантированной справедливости.

- **Spent execution time (vruntime):** это виртуальное время, которое процесс уже «провел» на процессоре (учитывает приоритет: у важных задач оно растет медленнее).
- **Зачем дерево:** CFS хранит процессы в **красно-чёрном дереве**, отсортированном по значению vruntime. Это позволяет быстро (за логарифмическое время) находить и удалять задачи.
- **Выбор «недополучившего»:** планировщик всегда берет крайний левый узел дерева (процесс с минимальным vruntime). Это гарантирует, что те, кто работал меньше всех, получат CPU первыми, стремясь к идеальному балансу.

#### **Сравните lottery scheduling и fair-share scheduling: что именно считается «справедливостью» в каждом, и в каких сценариях один подход предпочтительнее другого? ⭐⭐⭐**

- **Lottery Scheduling (Лотерейное планирование):**
    - **Справедливость:** вероятностная. Каждому процессу выдаются «билеты», и чем больше билетов, тем выше шанс выиграть квант времени.
    - **Предпочтительно:** когда нужно очень гибко и динамично менять доли ресурсов (например, процесс может отдать билеты своему серверу, пока ждет ответа).
- **Fair-Share Scheduling (Планирование по справедливости):**
    - **Справедливость:** на уровне владельца (пользователя). Если один пользователь запустил 10 процессов, а второй — 1, система распределит время так, чтобы каждый пользователь получил по 50% CPU.
    - **Предпочтительно:** в многопользовательских системах, чтобы не позволять одному юзеру захватить весь сервер простым созданием множества дочерних процессов.